# AI Street Interview Creation: A Documentation of the Workflow

This repository documents the detailed, iterative process of creating a short, AI-generated "deep fake" or **AI street interview** video using a large language model (LLM). The focus is on the **workflow** and the importance of precise, iterative prompting to achieve a desired creative outcome.

---

## 📂 Prior Research
This project builds upon previous research, including:
- [Task 05: Descriptive Stats](https://github.com/amankeskar/Task_05_Descriptive_Stats)
- Sports analysis and earlier LLM-driven creative experiments

---

## 🛠️ Project Methodology
The project followed a **three-phase workflow** centered on **prompt engineering** and **qualitative analysis**:

### Phase 1: Initial Prompt Formulation
- A comprehensive prompt was crafted to establish the **scene, characters, tone, and script**.
- **Scene**: On top of a giant pyramid, with desert and sky in the background.  
- **Characters**:  
  - Pikachu interviewer in a detective outfit, cheerful, saying "Pika" sometimes.  
  - Gorilla professor in a blazer and glasses, serious and analytical.  
- **Tone**: Comedic contrast.  
- **Script**:  
  - Pikachu asks: *"Pika pika? Who’s the fastest in baseball?"*  
  - Gorilla replies: *"The fastest MLB players sprint just over 30 miles per hour."*  
  - Pikachu: *"Pika! Faster than me?"*  
  - Gorilla: *"Definitely. Numbers don’t lie."*

**Outcome**:  
The video rendered the characters and setting correctly, but the **voices were generic**—failing to capture Pikachu’s squeakiness and the gorilla’s intended gravitas.

---

### Phase 2: Iterative Refinement
To fix the voice shortcomings, the prompt was refined with **explicit voice instructions**:
- Pikachu’s voice: *“squeaky like the real Pikachu voice.”*  
- Gorilla’s voice: *“deep, like Shaq’s voice.”*  

This was a turning point—using a **celebrity voice reference** helped guide the AI beyond generic synthesis.

---

### Phase 3: Final Generation & Analysis
- The refined prompt produced the **desired comedic dynamic**:
  - Pikachu’s squeaky pitch vs. Gorilla’s deep “Shaq-like” delivery.  
- The **contrast amplified the humor** and created a more authentic deep-fake effect.  

---

## 📌 How to Reproduce

If you’d like to replicate the workflow and experiment with your own AI street interviews:

1. **Choose Your AI Video Generator**  
   - Example: Veo3, Runway, Pika Labs, or any other text-to-video model with character/voice control.  

2. **Phase 1 – Draft the Initial Prompt**  
   - Define **scene, characters, tone, and dialogue** in detail.  
   - Keep it short (e.g., 8 seconds for comedic timing).  

3. **Generate & Review**  
   - Export the first video.  
   - Note where it falls short (e.g., voices, facial sync, comedic timing).  

4. **Phase 2 – Refine the Prompt**  
   - Add **voice references** (celebrity names, pitch levels, accents).  
   - Adjust scene or dialogue for better pacing.  

5. **Phase 3 – Finalize**  
   - Generate the improved version.  
   - Compare against the first attempt to analyze progress.  

6. **Iterate Further (Optional)**  
   - Keep refining until the comedic or narrative effect lands perfectly.  

---

## 🎯 Key Takeaways
- **AI creativity is iterative**: achieving quality requires testing, feedback, and refinement.  
- **Prompt engineering is crucial**: specific, contextual details (like celebrity voice anchors) dramatically improve results.  
- The role of the researcher is not just a user, but a **collaborative prompt engineer** guiding AI toward the creative vision.  

---

## 📌 Conclusion
This project demonstrates that **successful AI content generation = human guidance + AI iteration**.  
By combining **scene-setting, character design, and voice engineering**, the final video illustrates how carefully crafted prompts transform AI from a tool into a **creative partner**.  

---
